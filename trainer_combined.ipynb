{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4e14b95",
   "metadata": {},
   "source": [
    "# Cortex - A MRI Convolutional Neural Network \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc299c2e",
   "metadata": {},
   "source": [
    "## Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d4299",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627639f3",
   "metadata": {},
   "source": [
    "### Dependencies.\n",
    "\n",
    "We are going to lean heavily on `tensorflow` for the training, `matplotlib` for the visualisation, `pandas` for wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a0574e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "#---------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#---------------------------------------\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from typing import List, Dict, Tuple\n",
    "#---------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cadc8ae",
   "metadata": {},
   "source": [
    "### Constants, Paths and Training Params\n",
    "\n",
    "Defines a constants \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0245d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR: str = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "MODEL_DIR: str = os.path.join(os.getcwd(), \"models\")\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "MODEL_TYPE:str = \"cnn\"\n",
    "\n",
    "EPOCHS: int = 50\n",
    "PATIENCE: int = int(EPOCHS * 0.1)\n",
    "\n",
    "LEARNING_RATE: float = 0.001\n",
    "BETA1: float = 0.95\n",
    "BETA2: float = 0.999\n",
    "\n",
    "RANDOM_STATE: int = 42\n",
    "IMG_SIZE: Tuple[int,int] = (149,149)\n",
    "BATCH_SIZE: int = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa060037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_dir(model_type, model_name, base_dir=\"models\"):\n",
    "    #date_str: str = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    dir_path: str = os.path.join(base_dir, model_type, f\"{model_name}\")\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    return dir_path\n",
    "\n",
    "model_dir: str = init_model_dir(MODEL_TYPE.lower(), f\"cortex-{MODEL_TYPE.lower()}-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b54531a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU: /physical_device:CPU:0\n",
      "Using GPU: /physical_device:GPU:0\n",
      "TensorFlow version: 2.16.2\n"
     ]
    }
   ],
   "source": [
    "for device in tf.config.list_physical_devices():\n",
    "    if device.device_type == 'GPU':\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "        print(f\"Using GPU: {device.name}\")\n",
    "    else:\n",
    "        print(f\"Using CPU: {device.name}\")\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a91dfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5712 training images and 1311 test images.\n"
     ]
    }
   ],
   "source": [
    "train_dir: str = os.path.join(DATA_DIR, \"train\")\n",
    "test_dir: str = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    raise FileNotFoundError(f\"Data directory '{DATA_DIR}' does not exist.\")\n",
    "if not os.path.exists(train_dir):\n",
    "    raise FileNotFoundError(f\"Training data directory '{train_dir}' does not exist.\")\n",
    "if not os.path.exists(test_dir):\n",
    "    raise FileNotFoundError(f\"Test data directory '{test_dir}' does not exist.\")\n",
    "\n",
    "train_images: List[str] = glob(os.path.join(train_dir, \"*/*.jpg\"))\n",
    "test_images: List[str] = glob(os.path.join(test_dir, \"*/*.jpg\"))\n",
    "\n",
    "if not train_images:\n",
    "    raise FileNotFoundError(f\"No training images found in '{train_dir}'.\")\n",
    "if not test_images:\n",
    "    raise FileNotFoundError(f\"No test images found in '{test_dir}'.\")\n",
    "\n",
    "print(f\"Found {len(train_images)} training images and {len(test_images)} test images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f619e2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DataFrame shape: (5712, 3)\n",
      "Test DataFrame shape: (1311, 3)\n"
     ]
    }
   ],
   "source": [
    "def dataclassifier(path: str) -> pd.DataFrame:\n",
    "    records:List[Dict[str, str]] = []\n",
    "    img_paths: List[str] = glob(os.path.join(path, \"*/*.jpg\"))\n",
    "    for img_path in img_paths:\n",
    "        record: dict = {\n",
    "             \"img_path\": img_path,\n",
    "            \"level_1_class\": \"normal\" if img_path.split(os.sep)[-2] == \"notumor\" else \"abnormal\",\n",
    "            \"level_2_class\": img_path.split(os.sep)[-2]}\n",
    "        records.append(record)\n",
    "    df: pd.DataFrame = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "df_trn: pd.DataFrame = dataclassifier(train_dir)\n",
    "df_tst: pd.DataFrame = dataclassifier(test_dir)\n",
    "\n",
    "print(f\"Training DataFrame shape: {df_trn.shape}\")\n",
    "print(f\"Test DataFrame shape: {df_tst.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03076c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, df: pd.DataFrame ,x_col:str,y_col:str, img_size: Tuple[int, int], batch_size: int, shuffle: bool = True, randomize: bool = False):\n",
    "        self.df = df\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.randomize = randomize\n",
    "        self.x_col = x_col\n",
    "        self.y_col = y_col\n",
    "        \n",
    "        if randomize:\n",
    "            self.gen = self.flow_random()\n",
    "        else:\n",
    "            self.gen = self.flow()\n",
    "\n",
    "\n",
    "    def flow_random(self) -> tf.keras.utils.Sequence:\n",
    "        datagen: ImageDataGenerator = ImageDataGenerator(rescale=1./255)\n",
    "        gen = datagen.flow_from_dataframe(\n",
    "            dataframe = self.df,\n",
    "            x_col = self.x_col,\n",
    "            y_col = self.y_col,\n",
    "            target_size = self.img_size,\n",
    "            batch_size = self.batch_size,\n",
    "            class_mode = 'categorical',\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            rotation_range=25,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            brightness_range=[0.8, 1.2],\n",
    "            seed=RANDOM_STATE,\n",
    "        )\n",
    "        return gen\n",
    "    def flow(self) -> tf.keras.utils.Sequence:\n",
    "        datagen: ImageDataGenerator = ImageDataGenerator(rescale=1./255)\n",
    "        gen = datagen.flow_from_dataframe(\n",
    "            dataframe = self.df,\n",
    "            x_col = self.x_col,\n",
    "            y_col = self.y_col,\n",
    "            target_size = self.img_size,\n",
    "            batch_size = self.batch_size,\n",
    "            class_mode = 'categorical',\n",
    "        )\n",
    "        return gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7079b26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5712 validated image filenames belonging to 2 classes.\n",
      "Found 1311 validated image filenames belonging to 2 classes.\n",
      "Found 5712 validated image filenames belonging to 4 classes.\n",
      "Found 1311 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_lvl_1_gen = Generator(    df=df_trn,\n",
    "    x_col=\"img_path\",\n",
    "    y_col=\"level_1_class\",\n",
    "    img_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    randomize=True\n",
    ")\n",
    "test_lvl_1_gen = Generator(\n",
    "    df=df_tst,\n",
    "    x_col=\"img_path\",\n",
    "    y_col=\"level_1_class\",\n",
    "    img_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    randomize=False\n",
    ")\n",
    "train_lvl_2_gen = Generator(\n",
    "    df=df_trn,\n",
    "    x_col=\"img_path\",\n",
    "    y_col=\"level_2_class\",\n",
    "    img_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    randomize=True\n",
    ")\n",
    "test_lvl_2_gen = Generator(\n",
    "    df=df_tst,\n",
    "    x_col=\"img_path\",\n",
    "    y_col=\"level_2_class\",\n",
    "    img_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    randomize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c3979",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3621969",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_types_l1: int = len(train_lvl_1_gen.gen.class_indices)\n",
    "\n",
    "inputs = Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3), name='input')\n",
    "\n",
    "x = Conv2D(32, (4, 4), activation=\"relu\", kernel_regularizer=l2(0.001), name='conv_1')(inputs)\n",
    "x = MaxPooling2D(pool_size=(3, 3), name='pool_1')(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), activation=\"relu\", kernel_regularizer=l2(0.001), name='conv_2')(x)\n",
    "x = MaxPooling2D(pool_size=(3, 3), name='pool_2')(x)\n",
    "\n",
    "x = Conv2D(128, (4, 4), activation=\"relu\", kernel_regularizer=l2(0.001), name='conv_3')(x)\n",
    "x = MaxPooling2D(pool_size=(3, 3), name='pool_3')(x)\n",
    "\n",
    "x = Conv2D(128, (4, 4), activation=\"relu\", kernel_regularizer=l2(0.001), name='conv_4')(x)\n",
    "# No pooling here to match your original model\n",
    "x = Flatten(name='flatten')(x)\n",
    "\n",
    "x = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.001), name='fc_1')(x)\n",
    "x = Dropout(0.5, seed=RANDOM_STATE, name='dropout')(x)\n",
    "\n",
    "outputs = Dense(n_types_l1, activation=\"softmax\", name='output')(x)\n",
    "\n",
    "model_lvl_1 = Model(inputs=inputs, outputs=outputs, name='cortex_lvl1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "762af83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_types_l2: int = len(train_lvl_2_gen.gen.class_indices)\n",
    "\n",
    "inputs = Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3), name='input')\n",
    "\n",
    "x = Conv2D(32, (4, 4), activation=\"relu\", kernel_regularizer=l2(0.001), name='conv_1')(inputs)\n",
    "x = MaxPooling2D(pool_size=(3, 3), name='pool_1')(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), activation=\"relu\", kernel_regularizer=l2(0.001), name='conv_2')(x)\n",
    "x = MaxPooling2D(pool_size=(3, 3), name='pool_2')(x)\n",
    "\n",
    "x = Conv2D(128, (4, 4), activation=\"relu\", kernel_regularizer=l2(0.001), name='conv_3')(x)\n",
    "x = MaxPooling2D(pool_size=(3, 3), name='pool_3')(x)\n",
    "\n",
    "x = Conv2D(128, (4, 4), activation=\"relu\", kernel_regularizer=l2(0.001), name='conv_4')(x)\n",
    "# No pooling here to match your original model\n",
    "x = Flatten(name='flatten')(x)\n",
    "\n",
    "x = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.001), name='fc_1')(x)\n",
    "x = Dropout(0.5, seed=RANDOM_STATE, name='dropout')(x)\n",
    "\n",
    "outputs = Dense(n_types_l2, activation=\"softmax\", name='output')(x)\n",
    "\n",
    "model_lvl_2 = Model(inputs=inputs, outputs=outputs, name='cortex_lvl2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03818fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "optimizer_lvl_1 = Adam(learning_rate = LEARNING_RATE, beta_1=BETA1, beta_2=BETA2)\n",
    "optimizer_lvl_2 = Adam(learning_rate=LEARNING_RATE, beta_1=BETA1, beta_2=BETA2)\n",
    "\n",
    "model_lvl_1.compile(optimizer=optimizer_lvl_1, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_lvl_2.compile(optimizer=optimizer_lvl_2, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "train_model_lvl_1: tf.keras.callbacks.Callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=PATIENCE,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "train_model_lvl_2: tf.keras.callbacks.Callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=PATIENCE,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint_lvl_1: tf.keras.callbacks.Callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(model_dir, f\"cortex-{MODEL_TYPE.lower()}-lvl-1.keras\"),\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max'\n",
    ")\n",
    "model_checkpoint_lvl_2: tf.keras.callbacks.Callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(model_dir, f\"cortex-{MODEL_TYPE.lower()}-lvl-2.keras\"),\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "565b4abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_existing_model(filepath):\n",
    "    if os.path.exists(filepath):\n",
    "        try:\n",
    "            return load_model(filepath)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load model from {filepath}: {e}\")\n",
    "    return None\n",
    "\n",
    "def evaluate_model(model, val_data):\n",
    "    _, acc = model.evaluate(val_data, verbose=0)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def save_model_metadata(model, history, model_name, output_dir,train_data, val_data):\n",
    "    history_path = os.path.join(output_dir, f\"{model_name}_history.json\")\n",
    "    with open(history_path, 'w') as f:\n",
    "        json.dump(history.history, f)\n",
    "\n",
    "    summary_path = os.path.join(output_dir, f\"{model_name}_summary.txt\")\n",
    "    with open(summary_path, 'w') as f:\n",
    "        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "    arch_path = os.path.join(output_dir, f\"{model_name}_architecture.png\")\n",
    "    try:\n",
    "        plot_model(model, to_file=arch_path, show_shapes=True, show_layer_names=True)\n",
    "    except Exception as e:\n",
    "        print(\"Could not generate model diagram:\", e)\n",
    "        \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Plot Accuracy\n",
    "    if \"accuracy\" in history.history:\n",
    "        axs[0].plot(history.history[\"accuracy\"], label=\"train acc\")\n",
    "        axs[0].plot(history.history[\"val_accuracy\"], label=\"val acc\")\n",
    "        axs[0].set_ylim(0, 1)\n",
    "        axs[0].set_title(\"Training Accuracy\")\n",
    "        axs[0].set_xlabel(\"Epoch\")\n",
    "        axs[0].set_ylabel(\"Accuracy\")\n",
    "        axs[0].legend()\n",
    "\n",
    "    # Plot Loss\n",
    "    if \"loss\" in history.history:\n",
    "        axs[1].plot(history.history[\"loss\"], label=\"train loss\")\n",
    "        axs[1].plot(history.history[\"val_loss\"], label=\"val loss\")\n",
    "        axs[1].set_ylim(0, 1)\n",
    "        axs[1].set_title(\"Training Loss\")\n",
    "        axs[1].set_xlabel(\"Epoch\")\n",
    "        axs[1].set_ylabel(\"Loss\")\n",
    "        axs[1].legend()\n",
    "\n",
    "    # Save the combined plot\n",
    "    graph_path = os.path.join(output_dir, f\"{model_name}_training_plot.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(graph_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Save the Labels\n",
    "    labels_path = os.path.join(output_dir, f\"{model_name}_labels.json\")\n",
    "    with open(labels_path, 'w') as f:\n",
    "        json.dump(train_data.class_indices, f)\n",
    "    # Save the Configuration\n",
    "\n",
    "    config = \"\"\n",
    "    config += f\"Model Name: {model_name}\\n\"\n",
    "    config += f\"Model Type: {MODEL_TYPE}\\n\"\n",
    "    config += f\"Epochs: {EPOCHS}\\n\"\n",
    "    config += f\"Batch Size: {BATCH_SIZE}\\n\"\n",
    "    config += f\"Learning Rate: {LEARNING_RATE}\\n\"\n",
    "    config += f\"Beta1: {BETA1}\\n\"\n",
    "    config += f\"Beta2: {BETA2}\\n\"\n",
    "    config += f\"Random State: {RANDOM_STATE}\\n\"\n",
    "    config += f\"Image Size: {IMG_SIZE}\\n\"\n",
    "    config += f\"Training Data Size: {len(train_data)*BATCH_SIZE}\\n\"\n",
    "    config += f\"Validation Data Size: {len(val_data)*BATCH_SIZE}\\n\"\n",
    "    config_path = os.path.join(output_dir, f\"{model_name}_config.txt\")\n",
    "    with open(config_path, 'w') as f:\n",
    "        f.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e7fba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_path_lvl_1: str = os.path.join(model_dir, f\"cortex-{MODEL_TYPE.lower()}-lvl-1.keras\")\n",
    "existing_path_lvl_2: str = os.path.join(model_dir, f\"cortex-{MODEL_TYPE.lower()}-lvl-2.keras\")\n",
    "old_model_lvl_1 = load_existing_model(existing_path_lvl_1)\n",
    "old_model_lvl_2 = load_existing_model(existing_path_lvl_2)\n",
    "\n",
    "if old_model_lvl_1 is not None:\n",
    "    print(\"Evaluating existing Level 1 model...\")\n",
    "    evaluate_model(old_model_lvl_1, test_lvl_1_gen.gen)\n",
    "\n",
    "if old_model_lvl_2 is not None:\n",
    "    print(\"Evaluating existing Level 2 model...\")\n",
    "    evaluate_model(old_model_lvl_2, test_lvl_2_gen.gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7156f9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - accuracy: 0.8220 - loss: 0.6619 - val_accuracy: 0.9115 - val_loss: 0.3189\n",
      "Epoch 2/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9578 - loss: 0.2109 - val_accuracy: 0.9314 - val_loss: 0.2370\n",
      "Epoch 3/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.9724 - loss: 0.1573 - val_accuracy: 0.9497 - val_loss: 0.2045\n",
      "Epoch 4/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.9696 - loss: 0.1654 - val_accuracy: 0.9443 - val_loss: 0.1921\n",
      "Epoch 5/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.9797 - loss: 0.1218 - val_accuracy: 0.9680 - val_loss: 0.1533\n",
      "Epoch 6/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.9847 - loss: 0.1078 - val_accuracy: 0.9626 - val_loss: 0.1616\n",
      "Old Level 1 model accuracy: 0.0000\n",
      "New Level 1 model accuracy: 0.9680\n",
      "Improvement: 0.9680\n",
      "✅ New Level 1 model is better. Saving the new model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "history_lvl_1 = model_lvl_1.fit(\n",
    "    train_lvl_1_gen.gen,\n",
    "    validation_data=test_lvl_1_gen.gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[train_model_lvl_1],\n",
    "    verbose=1)\n",
    "\n",
    "# Compare and conditionally save\n",
    "new_accuracy = evaluate_model(model_lvl_1, test_lvl_1_gen.gen)\n",
    "old_accuracy = evaluate_model(old_model_lvl_1, test_lvl_1_gen.gen) if old_model_lvl_1 else 0\n",
    "print(f\"Old Level 1 model accuracy: {old_accuracy:.4f}\")\n",
    "print(f\"New Level 1 model accuracy: {new_accuracy:.4f}\")\n",
    "print(f\"Improvement: {new_accuracy - old_accuracy:.4f}\")\n",
    "\n",
    "if new_accuracy > old_accuracy:\n",
    "    print(\"✅ New Level 1 model is better. Saving the new model.\")\n",
    "    model_lvl_1.save(existing_path_lvl_1)\n",
    "    save_model_metadata(\n",
    "        model_lvl_1, history_lvl_1, \"cortex-cnn-lvl-1\", model_dir,train_data=train_lvl_1_gen.gen, val_data=test_lvl_1_gen.gen)\n",
    "else:\n",
    "    print(\"⚠️ Old Level 1 model is retained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4508adc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - accuracy: 0.4405 - loss: 1.3646 - val_accuracy: 0.7201 - val_loss: 0.7879\n",
      "Epoch 2/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.7576 - loss: 0.6829 - val_accuracy: 0.7452 - val_loss: 0.7320\n",
      "Epoch 3/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.8311 - loss: 0.5386 - val_accuracy: 0.7475 - val_loss: 0.7281\n",
      "Epoch 4/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.8603 - loss: 0.4890 - val_accuracy: 0.8322 - val_loss: 0.4779\n",
      "Epoch 5/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.9047 - loss: 0.3647 - val_accuracy: 0.8482 - val_loss: 0.5046\n",
      "Old Level 2 model accuracy: 0.0000\n",
      "New Level 2 model accuracy: 0.8322\n",
      "Improvement: 0.8322\n",
      "✅ New Level 2 model is better. Saving the new model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "history_lvl_2 = model_lvl_2.fit(\n",
    "    train_lvl_2_gen.gen,\n",
    "    validation_data=test_lvl_2_gen.gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[train_model_lvl_2],\n",
    "    verbose=1)\n",
    "\n",
    "# Compare and conditionally save\n",
    "new_accuracy = evaluate_model(model_lvl_2, test_lvl_2_gen.gen)\n",
    "old_accuracyz = evaluate_model(old_model_lvl_2, test_lvl_2_gen.gen) if old_model_lvl_2 else 0\n",
    "\n",
    "print(f\"Old Level 2 model accuracy: {old_accuracy:.4f}\")\n",
    "print(f\"New Level 2 model accuracy: {new_accuracy:.4f}\")\n",
    "print(f\"Improvement: {new_accuracy - old_accuracy:.4f}\")\n",
    "\n",
    "if new_accuracy > old_accuracy:\n",
    "    print(\"✅ New Level 2 model is better. Saving the new model.\")\n",
    "    model_lvl_2.save(existing_path_lvl_2)\n",
    "    save_model_metadata(\n",
    "        model_lvl_2, history_lvl_2, \"cortex-cnn-lvl-2\", model_dir,\n",
    "        train_data=train_lvl_2_gen.gen, val_data=test_lvl_2_gen.gen)\n",
    "else:\n",
    "    print(\"⚠️ Old Level 2 model is retained.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722025f5",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c34894f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cortex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
